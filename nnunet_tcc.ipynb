{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LLouzada/tcc/blob/master/nnunet_tcc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8LgbCLWNg6y",
        "outputId": "1061de6e-da8a-4193-aeb2-916108b9ce72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "### Preparação para instalação nnUNet (Executar toda vez que reiniciar runtime)\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Diretório de trabalho\n",
        "drive.mount('/content/drive',force_remount = False)\n",
        "base_dir = '/content/drive/My Drive/Colab Notebooks'\n",
        "os.chdir(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az3BtHCxNxgH"
      },
      "outputs": [],
      "source": [
        "### Clone do repositório nnUNet (if needed)\n",
        "\n",
        "#!rm -rf nnUNet\n",
        "\n",
        "\n",
        "#!git clone https://github.com/LLouzada/nnUNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gBeWPOQQNxbP",
        "outputId": "d1a67bf4-2725-433b-f654-620dd1f421df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/My%20Drive/Colab%20Notebooks/nnUNet\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (2.0.1+cu118)\n",
            "Collecting acvl-utils>=0.2 (from nnunetv2==2.2)\n",
            "  Downloading acvl_utils-0.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dynamic-network-architectures>=0.2 (from nnunetv2==2.2)\n",
            "  Downloading dynamic_network_architectures-0.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (4.66.1)\n",
            "Collecting dicom2nifti (from nnunetv2==2.2)\n",
            "  Downloading dicom2nifti-2.4.8-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (1.11.3)\n",
            "Collecting batchgenerators>=0.25 (from nnunetv2==2.2)\n",
            "  Downloading batchgenerators-0.25.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (0.19.3)\n",
            "Collecting SimpleITK>=2.2.1 (from nnunetv2==2.2)\n",
            "  Downloading SimpleITK-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (1.5.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (0.20.1)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (2023.9.26)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (2.31.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (4.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nnunetv2==2.2) (0.12.2)\n",
            "Collecting imagecodecs (from nnunetv2==2.2)\n",
            "  Downloading imagecodecs-2023.9.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yacs (from nnunetv2==2.2)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting connected-components-3d (from acvl-utils>=0.2->nnunetv2==2.2)\n",
            "  Downloading connected_components_3d-3.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2) (9.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2) (0.18.3)\n",
            "Collecting unittest2 (from batchgenerators>=0.25->nnunetv2==2.2)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2==2.2) (3.2.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2) (2.31.5)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.2) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->nnunetv2==2.2) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->nnunetv2==2.2) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.0->nnunetv2==2.2) (17.0.2)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2==2.2)\n",
            "  Downloading pydicom-2.4.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-gdcm (from dicom2nifti->nnunetv2==2.2)\n",
            "  Downloading python_gdcm-3.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2==2.2) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->nnunetv2==2.2) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2==2.2) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2==2.2) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunetv2==2.2) (1.3.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->nnunetv2==2.2) (6.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.2) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->nnunetv2==2.2) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->nnunetv2==2.2) (1.3.0)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2==2.2)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting traceback2 (from unittest2->batchgenerators>=0.25->nnunetv2==2.2)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2==2.2)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, dynamic-network-architectures\n",
            "  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.2-0.editable-py3-none-any.whl size=16210 sha256=47eac4b3b23e5ed666fb394b3048ad85f485bd2a2d46152b95225fd64faf5e1c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bqrtrgfo/wheels/55/72/64/b6b4021d54b80550b7aba5b71f265da8ef904c19c3ef9e4b54\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2-py3-none-any.whl size=22438 sha256=0f015a9e19b3e1515c14ad8cc8a4e76286b8b14212857e18034026035ec9821d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/f0/84/52e8897591e66339bd2796681b9540b6c5e453c1461fa92a9e\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25-py3-none-any.whl size=89008 sha256=d46c7647f3e5b07ef69769eb0bfde91056a7b61c51f883a489543ed6ad1be6f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/b0/1b/40912fb58eb167b86cbc444ddb2e6ba382b248215295f932e2\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.2-py3-none-any.whl size=27245 sha256=690219c66ed696426c50b70b918ebb4d66cc18f7ed0a46739ccbc48b1698e182\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/83/85/2ea6c18cc7d707fcd911586e8448ff8a9da1c0274e337f0e49\n",
            "Successfully built nnunetv2 acvl-utils batchgenerators dynamic-network-architectures\n",
            "Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, imagecodecs, connected-components-3d, unittest2, dicom2nifti, batchgenerators, dynamic-network-architectures, acvl-utils, nnunetv2\n",
            "Successfully installed SimpleITK-2.3.0 acvl-utils-0.2 argparse-1.4.0 batchgenerators-0.25 connected-components-3d-3.12.3 dicom2nifti-2.4.8 dynamic-network-architectures-0.2 imagecodecs-2023.9.18 linecache2-1.0.0 nnunetv2-2.2 pydicom-2.4.3 python-gdcm-3.0.22 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/FabianIsensee/hiddenlayer.git\n",
            "  Cloning https://github.com/FabianIsensee/hiddenlayer.git to /tmp/pip-req-build-oit13j6o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FabianIsensee/hiddenlayer.git /tmp/pip-req-build-oit13j6o\n",
            "  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit b7263b6dc4569da1b6dea5964e1eac78fa32fa77\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hiddenlayer\n",
            "  Building wheel for hiddenlayer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hiddenlayer: filename=hiddenlayer-0.2-py3-none-any.whl size=20004 sha256=ce84dbd14ba3fc4bede0a0318eb0d7a468a41cc780bda85b12122bcae75122bf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k_9u5txf/wheels/55/0e/e3/fdf2f92789305c0e320e0ab01f27fd4b757b1bb01c07d532c4\n",
            "Successfully built hiddenlayer\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.2\n"
          ]
        }
      ],
      "source": [
        "### Instalação (Executar toda vez que reiniciar runtime)\n",
        "\n",
        "respository_dir = os.path.join(base_dir,'nnUNet')\n",
        "os.chdir(respository_dir)\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "!pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git\n",
        "\n",
        "os.chdir(base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV5DdDqeN2r4"
      },
      "outputs": [],
      "source": [
        "### Unzip do dataset (if needed)\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "\n",
        "#drive.mount('/content/drive',force_remount = False)\n",
        "base_dir = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "nnUNet_dataset_root_dir = os.path.join(base_dir, 'nnUNet_dataset')\n",
        "nnUNet_dataset_raw_dir = os.path.join(nnUNet_dataset_root_dir, 'nnUNet_dataset_raw')\n",
        "nnunet_raw_dir = os.path.join(nnUNet_dataset_raw_dir, 'nnUNet_raw')\n",
        "\n",
        "os.chdir(nnUNet_dataset_root_dir)\n",
        "\n",
        "# change the file if needed\n",
        "zip_file = \"nnUNet_raw_v3.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(nnUNet_dataset_raw_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjdZGRk5N2kV"
      },
      "outputs": [],
      "source": [
        "# Run before running the cell below\n",
        "def make_if_dont_exist(folder_path,overwrite=False):\n",
        "    \"\"\"\n",
        "    creates a folder if it does not exists\n",
        "    input:\n",
        "    folder_path : relative path of the folder which needs to be created\n",
        "    over_write :(default: False) if True overwrite the existing folder\n",
        "    \"\"\"\n",
        "    if os.path.exists(folder_path):\n",
        "\n",
        "        if not overwrite:\n",
        "            print(f'{folder_path} exists.')\n",
        "        else:\n",
        "            print(f\"{folder_path} overwritten\")\n",
        "            shutil.rmtree(folder_path)\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    else:\n",
        "      os.makedirs(folder_path)\n",
        "      print(f\"{folder_path} created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHaNL7B_N4lB",
        "outputId": "194221aa-09d9-4f10-b0f0-f1c2083ba0e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "directories existence check:\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset exists.\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_dataset_raw/nnUNet_raw/Dataset001_SacroRM/imagesTr exists.\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_dataset_raw/nnUNet_raw/Dataset001_SacroRM/labelsTr exists.\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_dataset_raw/nnUNet_raw/Dataset001_SacroRM/imagesTs exists.\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_results exists.\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_preprocessed exists.\n",
            "environment variables check:\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_dataset_raw/nnUNet_raw\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_results\n",
            "/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_preprocessed\n",
            "We are in the correct directory\n"
          ]
        }
      ],
      "source": [
        "### nnUNet Setup\n",
        "\n",
        "# Libraries\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "import json\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import zipfile\n",
        "\n",
        "# Ambiente\n",
        "drive.mount('/content/drive',force_remount = False)\n",
        "base_dir = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "nnunet_dir = os.path.join(base_dir,'nnUNet')\n",
        "nnUNet_dataset_root_dir = os.path.join(base_dir, 'nnUNet_dataset')\n",
        "nnUNet_dataset_raw_dir = os.path.join(nnUNet_dataset_root_dir, 'nnUNet_dataset_raw')\n",
        "nnunet_raw_dir = os.path.join(nnUNet_dataset_raw_dir, 'nnUNet_raw')\n",
        "dataset_name = 'Dataset001_SacroRM'\n",
        "dataset_id = \"1\"\n",
        "dataset_dir = os.path.join(nnunet_raw_dir, dataset_name)\n",
        "train_image_dir = os.path.join(dataset_dir,'imagesTr')\n",
        "train_label_dir = os.path.join(dataset_dir,'labelsTr')\n",
        "test_dir = os.path.join(dataset_dir,'imagesTs')\n",
        "processed_dir = os.path.join(nnUNet_dataset_root_dir,'nnUNet_results')\n",
        "result_dir = os.path.join(nnUNet_dataset_root_dir,'nnUNet_preprocessed')\n",
        "\n",
        "# Checa se diretórios existem, caso conrario os cria\n",
        "!echo \"directories existence check:\"\n",
        "make_if_dont_exist(nnUNet_dataset_root_dir)\n",
        "make_if_dont_exist(train_image_dir)\n",
        "make_if_dont_exist(train_label_dir)\n",
        "make_if_dont_exist(test_dir)\n",
        "make_if_dont_exist(processed_dir)\n",
        "make_if_dont_exist(result_dir)\n",
        "\n",
        "# Env\n",
        "\n",
        "os.environ['nnUNet_raw'] = nnunet_raw_dir\n",
        "os.environ['nnUNet_preprocessed'] = processed_dir\n",
        "os.environ['nnUNet_results'] = result_dir\n",
        "\n",
        "# Checa se env está correto\n",
        "!echo \"environment variables check:\"\n",
        "!echo ${nnUNet_raw}\n",
        "!echo ${nnUNet_preprocessed}\n",
        "!echo ${nnUNet_results}\n",
        "\n",
        "os.chdir(base_dir)\n",
        "\n",
        "if os.getcwd()==base_dir:\n",
        "    print('We are in the correct directory')\n",
        "else:\n",
        "    print(\"Run set base directory step again, then check to verify.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkTHtL0Qf48Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "#colab users - mandatory\n",
        "\n",
        "\n",
        "# os.chdir('apex')\n",
        "\n",
        "# !pip install -v --no-cache-dir ./\n",
        "\n",
        "# os.chdir(base_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z2ZGlCKN64d"
      },
      "outputs": [],
      "source": [
        "!nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54OmSKY0N8Cg"
      },
      "outputs": [],
      "source": [
        "# Fold 0\n",
        "!nnUNetv2_train 001 2d 0 --c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brq6QeCDXpri"
      },
      "outputs": [],
      "source": [
        "# Fold 1\n",
        "!nnUNetv2_train 001 2d 1 --c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxUhuJelEF1k"
      },
      "outputs": [],
      "source": [
        "# Fold 2\n",
        "!nnUNetv2_train 001 2d 2 --c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfJM44mRj2me"
      },
      "outputs": [],
      "source": [
        "# Fold 3\n",
        "!nnUNetv2_train 001 2d 3 --c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fold 4\n",
        "!nnUNetv2_train 001 2d 4 --c --npz"
      ],
      "metadata": {
        "id": "Ov1Dvp3gzRQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the .npz for each fold (I forgot to add the arg --npz ;D )\n",
        "!nnUNetv2_train 001 2d 0 --val --npz"
      ],
      "metadata": {
        "id": "eAjSQZeRSRRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 001 2d 1 --val --npz"
      ],
      "metadata": {
        "id": "qdu-8XDJS2MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 001 2d 2 --val --npz"
      ],
      "metadata": {
        "id": "CUFbYYvJS1nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 001 2d 3 --val --npz"
      ],
      "metadata": {
        "id": "rzDppBK9S1cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_find_best_configuration 001 -c 2d"
      ],
      "metadata": {
        "id": "7_NynfZmTkP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_predict -d Dataset001_SacroRM -i '/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_dataset_raw/nnUNet_raw/Dataset001_SacroRM/imagesTs' -o '/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_prediction_results/Dataset001_SacroRM' -f  0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans"
      ],
      "metadata": {
        "id": "tIRnZb-HVT2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result1\n",
        "!nnUNetv2_predict -d Dataset001_SacroRM -i '/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_dataset_raw/nnUNet_raw/Dataset001_SacroRM/imagesTs' -o '/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_prediction_results/result1' -f  0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans"
      ],
      "metadata": {
        "id": "k7EhRsxmuKp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result2\n",
        "!nnUNetv2_predict -d Dataset001_SacroRM -i '/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_dataset_raw/nnUNet_raw/Dataset001_SacroRM/imagesTs' -o '/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_prediction_results/result2' -f  0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans"
      ],
      "metadata": {
        "id": "eHdU43iPubOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result3\n",
        "!nnUNetv2_predict -d Dataset001_SacroRM -i '/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_dataset_raw/nnUNet_raw/Dataset001_SacroRM/imagesTs' -o '/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_prediction_results/result3' -f  0 1 2 3 4 -tr nnUNetTrainer -c 2d -p nnUNetPlans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhaAWaTKWzwZ",
        "outputId": "466ce0dc-7720-4d8d-d8a2-053b351c81f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "There are 2 cases in the source folder\n",
            "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
            "There are 2 cases that I would like to predict\n",
            "\n",
            "Predicting SRM_052:\n",
            "perform_everything_on_gpu: True\n",
            "100% 1/1 [00:08<00:00,  8.08s/it]\n",
            "100% 1/1 [00:00<00:00, 32.66it/s]\n",
            "100% 1/1 [00:00<00:00, 31.77it/s]\n",
            "100% 1/1 [00:00<00:00, 31.12it/s]\n",
            "100% 1/1 [00:00<00:00, 31.23it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with SRM_052\n",
            "\n",
            "Predicting SRM_115:\n",
            "perform_everything_on_gpu: True\n",
            "100% 1/1 [00:00<00:00, 27.84it/s]\n",
            "100% 1/1 [00:00<00:00, 30.76it/s]\n",
            "100% 1/1 [00:00<00:00, 23.61it/s]\n",
            "100% 1/1 [00:00<00:00, 30.89it/s]\n",
            "100% 1/1 [00:00<00:00, 29.65it/s]\n",
            "Prediction done, transferring to CPU if needed\n",
            "sending off prediction to background worker for resampling and export\n",
            "done with SRM_115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Post Processing\n",
        "!nnUNetv2_apply_postprocessing -i \"/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_prediction_results/result3\" -o \"/content/drive/MyDrive/Colab Notebooks/nnUNet_dataset/nnUNet_prediction_results/result3_pp\" -pp_pkl_file \"/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_preprocessed/Dataset001_SacroRM/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/postprocessing.pkl\" -np 8 -plans_json \"/content/drive/My Drive/Colab Notebooks/nnUNet_dataset/nnUNet_preprocessed/Dataset001_SacroRM/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/plans.json\"\n"
      ],
      "metadata": {
        "id": "ithmLWO-hylC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQ2W2Xb6+o0nvJhAw03vPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}